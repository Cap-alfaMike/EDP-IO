# ============================================================================
# EDP-IO - Schema Drift Detection
# ============================================================================
"""
Schema drift detection with LLM-powered impact assessment.

WHAT IS SCHEMA DRIFT?
--------------------
Schema drift occurs when source systems change their structure without
coordination. Common scenarios:
- New columns added
- Columns removed or renamed
- Data type changes
- Constraint changes (nullable ‚Üí not null)

WHY LLM FOR ASSESSMENT?
----------------------
Traditional schema checks detect WHAT changed. LLM helps assess:
- Business impact of the change
- Which downstream models are affected
- Recommended remediation priority
- Whether change is breaking or additive

SAFETY:
------
- LLM only assesses impact, never modifies schemas
- All recommendations require human approval
- Feature flag to disable LLM entirely
"""

import json
from dataclasses import dataclass, field
from datetime import datetime, timezone
from enum import Enum
from typing import Any, Dict, List, Optional, Set

from pydantic import BaseModel, Field

from src.utils.config import get_settings
from src.utils.logging import get_logger
from src.utils.security import SecretProvider

logger = get_logger(__name__)


class ChangeType(str, Enum):
    """Types of schema changes."""

    COLUMN_ADDED = "COLUMN_ADDED"
    COLUMN_REMOVED = "COLUMN_REMOVED"
    COLUMN_RENAMED = "COLUMN_RENAMED"
    TYPE_CHANGED = "TYPE_CHANGED"
    NULLABLE_CHANGED = "NULLABLE_CHANGED"
    CONSTRAINT_ADDED = "CONSTRAINT_ADDED"
    CONSTRAINT_REMOVED = "CONSTRAINT_REMOVED"


class DriftSeverity(str, Enum):
    """Severity of schema drift."""

    INFO = "INFO"  # Additive, non-breaking
    WARNING = "WARNING"  # Potential impact, review recommended
    ERROR = "ERROR"  # Breaking change, action required
    CRITICAL = "CRITICAL"  # Immediate action required


@dataclass
class SchemaColumn:
    """Represents a column in a schema."""

    name: str
    data_type: str
    nullable: bool = True
    description: Optional[str] = None

    def to_dict(self) -> Dict[str, Any]:
        return {
            "name": self.name,
            "data_type": self.data_type,
            "nullable": self.nullable,
            "description": self.description,
        }


@dataclass
class SchemaChange:
    """Represents a single schema change."""

    change_type: ChangeType
    column_name: str
    old_value: Optional[str] = None
    new_value: Optional[str] = None

    def to_dict(self) -> Dict[str, Any]:
        return {
            "change_type": self.change_type.value,
            "column_name": self.column_name,
            "old_value": self.old_value,
            "new_value": self.new_value,
        }


class DriftReport(BaseModel):
    """
    Structured drift report with LLM assessment.

    Generated by comparing expected vs. actual schemas.
    """

    table_name: str = Field(description="Table that has drifted")
    source_system: str = Field(description="Source system (oracle_erp, sqlserver_ecommerce)")
    detected_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))

    changes: List[Dict[str, Any]] = Field(
        default_factory=list, description="List of detected changes"
    )

    severity: DriftSeverity = Field(
        default=DriftSeverity.WARNING, description="Overall severity of the drift"
    )

    breaking_change: bool = Field(default=False, description="Whether any change is breaking")

    affected_downstream: List[str] = Field(
        default_factory=list, description="Downstream models/tables affected"
    )

    business_impact: str = Field(default="", description="LLM-generated business impact assessment")

    recommended_actions: List[str] = Field(
        default_factory=list, description="Ordered list of remediation steps"
    )

    requires_human_approval: bool = Field(
        default=True, description="Always True - humans must approve actions"
    )

    confidence_score: float = Field(
        default=0.0, ge=0.0, le=1.0, description="LLM confidence in assessment"
    )


class SchemaDriftDetector:
    """
    Detects and assesses schema drift between expected and actual schemas.

    USAGE:
        detector = SchemaDriftDetector()

        # Compare schemas
        report = detector.detect_drift(
            table_name="customers",
            expected_schema=data_contract_schema,
            actual_schema=current_schema,
        )

        if report.breaking_change:
            alert_team(report)

    BEHAVIOR:
    - Detection: Pure Python comparison (always works)
    - Assessment: LLM-powered when enabled, mock otherwise
    """

    # Lineage of bronze ‚Üí silver ‚Üí gold
    DOWNSTREAM_LINEAGE = {
        "customers": ["stg_customers", "dim_customer", "fact_sales"],
        "products": ["stg_products", "dim_product", "fact_sales"],
        "orders": ["stg_orders", "fact_sales"],
        "order_items": ["fact_sales"],
        "stores": ["dim_store"],
    }

    SYSTEM_PROMPT = """You are a data platform expert assessing schema drift impact.

CONTEXT:
- EDP-IO is a retail data platform with Bronze/Silver/Gold layers
- Schema drift can break pipelines and affect downstream analytics

YOUR ROLE:
- Assess business impact of schema changes
- Identify affected downstream models
- Recommend prioritized remediation actions
- NEVER suggest auto-fixing - humans must approve

OUTPUT FORMAT (JSON):
{
    "severity": "INFO|WARNING|ERROR|CRITICAL",
    "breaking_change": true/false,
    "business_impact": "Description of business impact",
    "affected_downstream": ["model1", "model2"],
    "recommended_actions": ["Action 1", "Action 2"],
    "confidence_score": 0.0-1.0
}"""

    def __init__(self):
        """Initialize the drift detector."""
        self.settings = get_settings()
        self._client = None

        logger.info(
            "SchemaDriftDetector initialized",
            llm_enabled=self.settings.enable_llm_observability,
        )

    @property
    def is_enabled(self) -> bool:
        """Check if LLM assessment is enabled."""
        return self.settings.enable_llm_observability

    def _compare_schemas(
        self,
        expected: List[SchemaColumn],
        actual: List[SchemaColumn],
    ) -> List[SchemaChange]:
        """
        Compare expected and actual schemas.

        This is pure Python comparison - no LLM involved.
        """
        changes = []

        expected_cols = {col.name: col for col in expected}
        actual_cols = {col.name: col for col in actual}

        expected_names = set(expected_cols.keys())
        actual_names = set(actual_cols.keys())

        # New columns
        for col_name in actual_names - expected_names:
            changes.append(
                SchemaChange(
                    change_type=ChangeType.COLUMN_ADDED,
                    column_name=col_name,
                    new_value=actual_cols[col_name].data_type,
                )
            )

        # Removed columns
        for col_name in expected_names - actual_names:
            changes.append(
                SchemaChange(
                    change_type=ChangeType.COLUMN_REMOVED,
                    column_name=col_name,
                    old_value=expected_cols[col_name].data_type,
                )
            )

        # Changed columns
        for col_name in expected_names & actual_names:
            exp = expected_cols[col_name]
            act = actual_cols[col_name]

            if exp.data_type != act.data_type:
                changes.append(
                    SchemaChange(
                        change_type=ChangeType.TYPE_CHANGED,
                        column_name=col_name,
                        old_value=exp.data_type,
                        new_value=act.data_type,
                    )
                )

            if exp.nullable != act.nullable:
                changes.append(
                    SchemaChange(
                        change_type=ChangeType.NULLABLE_CHANGED,
                        column_name=col_name,
                        old_value=str(exp.nullable),
                        new_value=str(act.nullable),
                    )
                )

        return changes

    def _is_breaking(self, changes: List[SchemaChange]) -> bool:
        """Determine if any change is breaking."""
        breaking_types = {
            ChangeType.COLUMN_REMOVED,
            ChangeType.TYPE_CHANGED,
        }

        for change in changes:
            if change.change_type in breaking_types:
                return True
            # Nullable ‚Üí Not Null is breaking
            if (
                change.change_type == ChangeType.NULLABLE_CHANGED
                and change.old_value == "True"
                and change.new_value == "False"
            ):
                return True

        return False

    def _get_downstream(self, table_name: str) -> List[str]:
        """Get downstream models for a table."""
        return self.DOWNSTREAM_LINEAGE.get(table_name, [])

    def _get_mock_assessment(
        self,
        table_name: str,
        changes: List[SchemaChange],
    ) -> Dict[str, Any]:
        """Generate mock assessment when LLM is disabled."""
        is_breaking = self._is_breaking(changes)

        # Generate appropriate mock response
        if not changes:
            return {
                "severity": DriftSeverity.INFO.value,
                "breaking_change": False,
                "business_impact": "No schema changes detected",
                "affected_downstream": [],
                "recommended_actions": ["No action required"],
                "confidence_score": 1.0,
            }

        if is_breaking:
            return {
                "severity": DriftSeverity.ERROR.value,
                "breaking_change": True,
                "business_impact": f"Breaking change detected in {table_name}. Downstream models will fail until corrected.",
                "affected_downstream": self._get_downstream(table_name),
                "recommended_actions": [
                    "Pause affected pipelines",
                    "Coordinate with source team",
                    "Update data contracts",
                    "Modify transformation logic",
                    "Reprocess affected partitions",
                ],
                "confidence_score": 0.85,
            }
        else:
            return {
                "severity": DriftSeverity.WARNING.value,
                "breaking_change": False,
                "business_impact": f"Additive changes to {table_name}. Review for potential analytics value.",
                "affected_downstream": self._get_downstream(table_name),
                "recommended_actions": [
                    "Review new columns with business team",
                    "Update data contracts if adopting",
                    "Consider adding to downstream models",
                ],
                "confidence_score": 0.80,
            }

    def detect_drift(
        self,
        table_name: str,
        expected_schema: List[SchemaColumn],
        actual_schema: List[SchemaColumn],
        source_system: str = "unknown",
    ) -> DriftReport:
        """
        Detect and assess schema drift.

        Args:
            table_name: Name of the table being checked
            expected_schema: Schema from data contract
            actual_schema: Current schema from source
            source_system: Source system identifier

        Returns:
            DriftReport with changes and LLM assessment
        """
        logger.info(
            "Detecting schema drift",
            table=table_name,
            llm_enabled=self.is_enabled,
        )

        # Step 1: Compare schemas (pure Python)
        changes = self._compare_schemas(expected_schema, actual_schema)

        if not changes:
            logger.info("No schema drift detected", table=table_name)
            return DriftReport(
                table_name=table_name,
                source_system=source_system,
                changes=[],
                severity=DriftSeverity.INFO,
                business_impact="No schema changes detected",
                requires_human_approval=True,
            )

        logger.warning(
            "Schema drift detected",
            table=table_name,
            change_count=len(changes),
        )

        # Step 2: Assess impact (LLM or mock)
        if self.is_enabled:
            assessment = self._llm_assess(table_name, changes)
        else:
            assessment = self._get_mock_assessment(table_name, changes)

        # Build report
        return DriftReport(
            table_name=table_name,
            source_system=source_system,
            changes=[c.to_dict() for c in changes],
            severity=DriftSeverity(assessment["severity"]),
            breaking_change=assessment["breaking_change"],
            affected_downstream=assessment["affected_downstream"],
            business_impact=assessment["business_impact"],
            recommended_actions=assessment["recommended_actions"],
            requires_human_approval=True,  # Always True
            confidence_score=assessment["confidence_score"],
        )

    def _llm_assess(
        self,
        table_name: str,
        changes: List[SchemaChange],
    ) -> Dict[str, Any]:
        """Use LLM to assess drift impact."""
        try:
            from openai import AzureOpenAI

            api_key = SecretProvider.get("AZURE_OPENAI_KEY")

            client = AzureOpenAI(
                api_key=api_key,
                api_version=self.settings.azure_openai_api_version,
                azure_endpoint=self.settings.azure_openai_endpoint,
            )

            user_message = f"""Assess the impact of these schema changes:

Table: {table_name}
Changes:
{json.dumps([c.to_dict() for c in changes], indent=2)}

Known downstream models: {self._get_downstream(table_name)}
"""

            response = client.chat.completions.create(
                model=self.settings.azure_openai_deployment_name,
                messages=[
                    {"role": "system", "content": self.SYSTEM_PROMPT},
                    {"role": "user", "content": user_message},
                ],
                temperature=0.3,
                max_tokens=800,
                response_format={"type": "json_object"},
            )

            return json.loads(response.choices[0].message.content)

        except Exception as e:
            logger.error("LLM assessment failed", error=str(e))
            return self._get_mock_assessment(table_name, changes)

    def format_report(self, report: DriftReport) -> str:
        """Format report for human display."""
        severity_emoji = {
            DriftSeverity.INFO: "‚ÑπÔ∏è",
            DriftSeverity.WARNING: "‚ö†Ô∏è",
            DriftSeverity.ERROR: "‚ùå",
            DriftSeverity.CRITICAL: "üö®",
        }

        changes_text = (
            "\n".join(
                [
                    f"  - {c['change_type']}: {c['column_name']} ({c.get('old_value', 'N/A')} ‚Üí {c.get('new_value', 'N/A')})"
                    for c in report.changes
                ]
            )
            or "  No changes"
        )

        actions_text = (
            "\n".join([f"  {i+1}. {action}" for i, action in enumerate(report.recommended_actions)])
            or "  No actions required"
        )

        return f"""
{severity_emoji.get(report.severity, "‚ùì")} **Schema Drift Report: {report.table_name}**
Source: {report.source_system} | Detected: {report.detected_at.strftime('%Y-%m-%d %H:%M UTC')}

**Changes:**
{changes_text}

**Breaking Change:** {'üî¥ YES' if report.breaking_change else 'üü¢ NO'}

**Business Impact:**
{report.business_impact}

**Affected Downstream:**
{', '.join(report.affected_downstream) or 'None identified'}

**Recommended Actions:**
{actions_text}

‚ö†Ô∏è **Human approval required before any action**
Confidence: {report.confidence_score:.0%}
"""
